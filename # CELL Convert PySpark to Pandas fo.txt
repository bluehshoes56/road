# CELL 6: Train VAE Model - Complete Updated Version

import datetime
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Ensure we're using the real dataset
print(f"Original data shape: {original_data.shape}")
print(f"Processed data shape: {processed_data.shape if 'processed_data' in locals() else 'NOT FOUND'}")

# If processed_data doesn't match original_data size, reprocess
if 'processed_data' not in locals() or len(processed_data) != len(original_data):
    print("Re-processing original data for training...")
    processed_data = processor.fit_transform(original_data)
    print(f"New processed data shape: {processed_data.shape}")

print("üöÄ Starting VAE training...")
print(f"Dataset: {config.CURRENT_SIZE} ({len(original_data):,} rows)")
print(f"Expected training time: {2 if config.CURRENT_SIZE == 'TEST' else 10} minutes")

# Improved data normalization with numerical stability
train_data = (processed_data - processed_data.min()) / (processed_data.max() - processed_data.min() + 1e-8)

print(f"Training data shape: {train_data.shape}")

# Train the model with improved configuration
start_time = datetime.datetime.now()

print("üîß Training VAE model with improved parameters...")
history = vae_model.train(
    train_data,
    epochs=100,
    batch_size=128,  # Smaller batch size for stability
    verbose=1
)

end_time = datetime.datetime.now()
training_duration = (end_time - start_time).total_seconds() / 60

print(f"\n‚úÖ Training completed in {training_duration:.1f} minutes")

# Validate training quality
final_loss = min(history.history['loss'])

print(f"\nüìä Training Quality Assessment:")
print(f"   Final training loss: {final_loss:.4f}")

if final_loss > 50:
    print("‚ö†Ô∏è WARNING: High loss suggests poor training quality")
    print("   Consider adjusting learning rate or model architecture")
elif final_loss < 10:
    print("‚úÖ Good training quality - loss converged well")
else:
    print("‚ö° Moderate training quality - acceptable for synthetic generation")

# Plot training history
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss', linewidth=2)
plt.title('VAE Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
# Plot loss improvement rate
loss_values = history.history['loss']
improvement_rate = [0] + [loss_values[i-1] - loss_values[i] for i in range(1, len(loss_values))]
plt.plot(improvement_rate, label='Loss Improvement', color='green', linewidth=2)
plt.title('Training Progress')
plt.xlabel('Epoch')
plt.ylabel('Loss Reduction')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Additional diagnostics
print(f"\nüîç Training Diagnostics:")
print(f"   Total epochs completed: {len(history.history['loss'])}")
print(f"   Best epoch (lowest loss): {np.argmin(history.history['loss']) + 1}")
print(f"   Loss reduction: {history.history['loss'][0]:.4f} ‚Üí {final_loss:.4f}")

# Test generation capability
print(f"\nüß™ Testing generation capability...")
test_samples = vae_model.generate(5)
print(f"   Test generation shape: {test_samples.shape}")
print(f"   Test generation range: [{test_samples.min():.4f}, {test_samples.max():.4f}]")

print(f"\nüéâ VAE model training successful!")
print(f"Ready to generate synthetic data.")
