# CELL 4: Data Preprocessing

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer

class DatabricksDataProcessor:
    """Databricks-optimized data preprocessing for financial data."""
    
    def __init__(self, config):
        self.config = config
        self.label_encoders = {}
        self.numerical_scaler = StandardScaler()
        self.fitted = False
        self.feature_dim = 0
    
    def fit_transform(self, data: pd.DataFrame) -> np.ndarray:
        """Fit and transform data in one step."""
        print("Preprocessing data for VAE training...")
        
        # Validate data
        self._validate_data(data)
        
        processed_features = []
        
        # Process categorical columns
        for col in self.config.CATEGORICAL_COLUMNS:
            if col in data.columns:
                # Handle missing values
                clean_data = data[col].fillna('Unknown').astype(str)
                
                # Fit and transform
                encoder = LabelEncoder()
                encoded = encoder.fit_transform(clean_data)
                
                # One-hot encode
                n_classes = len(encoder.classes_)
                one_hot = np.eye(n_classes)[encoded]
                processed_features.append(one_hot)
                
                self.label_encoders[col] = encoder
                print(f"  {col}: {n_classes} categories")
        
        # Process numerical columns
        numerical_features = []
        for col in self.config.NUMERICAL_COLUMNS:
            if col in data.columns:
                numerical_features.append(data[col].values.reshape(-1, 1))
        
        if numerical_features:
            numerical_data = np.hstack(numerical_features)
            numerical_decoded = self.numerical_scaler.fit_transform(numerical_data)
            processed_features.append(numerical_decoded)
        
        # Combine all features
        result_data = np.hstack(processed_features)
        self.feature_dim = result_data.shape[1]
        self.fitted = True
        
        print(f"‚úÖ Data preprocessing completed!")
        print(f"Ready for VAE training with {original_data.shape[0]} samples and {result_data.shape[1]} features")
        
        return result_data
    
    def _validate_data(self, data: pd.DataFrame):
        """Validate input data."""
        required_cols = self.config.CATEGORICAL_COLUMNS + self.config.NUMERICAL_COLUMNS
        missing_cols = [col for col in required_cols if col not in data.columns]
        
        if missing_cols:
            raise ValueError(f"Missing required columns: {missing_cols}")
        
        print(f"Data validation passed: {len(data)} rows, {len(data.columns)} columns")

# Initialize and fit processor
processor = DatabricksDataProcessor(config)
processed_data = processor.fit_transform(original_data)

print(f"üîç Data preprocessing complete!")
print(f"Original data shape: {original_data.shape}")
print(f"Processed data shape: {processed_data.shape}")
