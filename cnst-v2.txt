# COMMAND ----------
# Enhanced Constant Merchant Dashboard - Fixed Version
# Handles data type issues and creates robust dashboard DataFrames

from pyspark.sql.functions import col, countDistinct, sum as spark_sum, avg, when, lit, broadcast
import pandas as pd

print("Enhanced Constant Merchant Dashboard Analysis - Fixed Version")

# COMMAND ----------
# Define periods
period2_months = [202101, 202102, 202103, 202104, 202105, 202106,
                  202107, 202108, 202109, 202110, 202111, 202112,
                  202201, 202202]  # 14-month base period

# Get tracking months
available_months = gbs_mids_joined.select("txn_year_month").distinct().collect()
available_months_list = sorted([row.txn_year_month for row in available_months])

tracking_months = [202202]  # Start with baseline
for year_month in available_months_list:
    if int(year_month) > 202202:
        year = int(year_month) // 100
        month = int(year_month) % 100
        if month in [3, 6, 9, 12]:  # Quarterly endpoints
            tracking_months.append(year_month)

print(f"Dashboard tracking periods: {tracking_months}")

# COMMAND ----------
# Identify constant merchants
period2_data = gbs_mids_joined.filter(col("txn_year_month").isin(period2_months))
merchants_14m_counts = period2_data.groupBy("merchant_key").agg(
    countDistinct("txn_year_month").alias("months_present")
)

constant_merchants_14m = merchants_14m_counts.filter(col("months_present") == 14).select("merchant_key")
constant_14m_count = constant_merchants_14m.count()

print(f"Base cohort: {constant_14m_count:,} constant merchants")

# COMMAND ----------
# Dashboard DataFrame 1: High-Level Summary
print("\n=== Creating High-Level Summary Dashboard ===")

summary_data = []

for month in tracking_months:
    if month in available_months_list:
        print(f"Processing period: {month}")
        
        monthly_data = gbs_mids_joined \
            .filter(col("txn_year_month") == month) \
            .join(broadcast(constant_merchants_14m), on="merchant_key", how="inner")
        
        # Get aggregated stats
        stats = monthly_data.agg(
            countDistinct("merchant_key").alias("active_merchants"),
            spark_sum(col("adjusted_txn_cnt")).alias("total_transactions"),
            spark_sum(col("total_tran_amount")).alias("total_amount")
        ).collect()[0]
        
        # Safe extraction of values
        active_merchants = stats['active_merchants'] or 0
        total_transactions = stats['total_transactions'] or 0
        total_amount = stats['total_amount'] or 0
        
        # Calculate derived metrics
        retention_rate = (active_merchants / constant_14m_count * 100) if constant_14m_count > 0 else 0
        avg_txn_amount = (total_amount / total_transactions) if total_transactions > 0 else 0
        avg_merchant_amount = (total_amount / active_merchants) if active_merchants > 0 else 0
        
        summary_data.append({
            'period': int(month),
            'active_merchants': int(active_merchants),
            'retention_rate_pct': round(float(retention_rate), 2),
            'total_transactions': int(total_transactions),
            'total_amount': float(total_amount),
            'avg_transaction_amount': round(float(avg_txn_amount), 2),
            'avg_merchant_amount': round(float(avg_merchant_amount), 2),
            'base_cohort_size': int(constant_14m_count)
        })

df_summary = pd.DataFrame(summary_data)
print(f"Summary DataFrame created: {len(df_summary)} periods")

# COMMAND ----------
# Dashboard DataFrame 2: Industry Performance (NAICS3)
print("\n=== Creating Industry Performance Dashboard ===")

industry_data = []

for month in tracking_months:
    if month in available_months_list:
        monthly_data = gbs_mids_joined \
            .filter(col("txn_year_month") == month) \
            .join(broadcast(constant_merchants_14m), on="merchant_key", how="inner")
        
        # Group by NAICS3
        naics_stats = monthly_data.groupBy("naics3").agg(
            countDistinct("merchant_key").alias("merchants"),
            spark_sum(col("adjusted_txn_cnt")).alias("transactions"),
            spark_sum(col("total_tran_amount")).alias("amount")
        ).collect()
        
        for row in naics_stats:
            merchants = row['merchants'] or 0
            transactions = row['transactions'] or 0
            amount = row['amount'] or 0
            
            industry_data.append({
                'period': int(month),
                'naics3': str(row['naics3']),
                'merchants': int(merchants),
                'transactions': int(transactions),
                'amount': float(amount),
                'avg_per_merchant': round(float(amount / merchants), 2) if merchants > 0 else 0,
                'avg_per_transaction': round(float(amount / transactions), 2) if transactions > 0 else 0
            })

df_industry = pd.DataFrame(industry_data)
print(f"Industry DataFrame created: {len(df_industry)} records")

# COMMAND ----------
# Dashboard DataFrame 3: Retention Analysis by Industry
print("\n=== Creating Retention Analysis Dashboard ===")

# Get baseline counts by NAICS3
baseline_data = gbs_mids_joined \
    .filter(col("txn_year_month").isin(period2_months)) \
    .join(broadcast(constant_merchants_14m), on="merchant_key", how="inner") \
    .groupBy("naics3") \
    .agg(countDistinct("merchant_key").alias("baseline_merchants")) \
    .collect()

baseline_dict = {str(row['naics3']): row['baseline_merchants'] for row in baseline_data}

retention_data = []

for month in tracking_months:
    if month in available_months_list:
        monthly_data = gbs_mids_joined \
            .filter(col("txn_year_month") == month) \
            .join(broadcast(constant_merchants_14m), on="merchant_key", how="inner")
        
        retention_stats = monthly_data.groupBy("naics3").agg(
            countDistinct("merchant_key").alias("active_merchants")
        ).collect()
        
        for row in retention_stats:
            naics3 = str(row['naics3'])
            active = row['active_merchants'] or 0
            baseline = baseline_dict.get(naics3, 1)
            retention_rate = (active / baseline * 100) if baseline > 0 else 0
            
            retention_data.append({
                'period': int(month),
                'naics3': naics3,
                'baseline_merchants': int(baseline),
                'active_merchants': int(active),
                'retention_rate_pct': round(float(retention_rate), 2)
            })

df_retention = pd.DataFrame(retention_data)
print(f"Retention DataFrame created: {len(df_retention)} records")

# COMMAND ----------
# Dashboard DataFrame 4: Top Industries Analysis
print("\n=== Creating Top Industries Dashboard ===")

# Calculate overall performance by industry
top_industries = df_industry.groupby('naics3').agg({
    'merchants': 'mean',
    'transactions': 'sum',
    'amount': 'sum',
    'avg_per_merchant': 'mean'
}).reset_index()

top_industries.columns = ['naics3', 'avg_merchants', 'total_transactions', 'total_amount', 'avg_per_merchant']
top_industries = top_industries.sort_values('total_amount', ascending=False).head(15)

# Round values
for col in ['avg_merchants', 'avg_per_merchant']:
    top_industries[col] = top_industries[col].round(2)

df_top_industries = top_industries.reset_index(drop=True)
print(f"Top Industries DataFrame created: {len(df_top_industries)} industries")

# COMMAND ----------
# Dashboard DataFrame 5: Growth Trends
print("\n=== Creating Growth Trends Dashboard ===")

df_summary_sorted = df_summary.sort_values('period').reset_index(drop=True)
growth_data = []

for i in range(1, len(df_summary_sorted)):
    current = df_summary_sorted.iloc[i]
    previous = df_summary_sorted.iloc[i-1]
    
    # Calculate growth rates
    merchant_growth = ((current['active_merchants'] - previous['active_merchants']) / previous['active_merchants'] * 100) if previous['active_merchants'] > 0 else 0
    transaction_growth = ((current['total_transactions'] - previous['total_transactions']) / previous['total_transactions'] * 100) if previous['total_transactions'] > 0 else 0
    amount_growth = ((current['total_amount'] - previous['total_amount']) / previous['total_amount'] * 100) if previous['total_amount'] > 0 else 0
    retention_change = current['retention_rate_pct'] - previous['retention_rate_pct']
    
    growth_data.append({
        'period': int(current['period']),
        'previous_period': int(previous['period']),
        'merchant_growth_pct': round(float(merchant_growth), 2),
        'transaction_growth_pct': round(float(transaction_growth), 2),
        'amount_growth_pct': round(float(amount_growth), 2),
        'retention_change_pct': round(float(retention_change), 2)
    })

df_growth = pd.DataFrame(growth_data)
print(f"Growth Trends DataFrame created: {len(df_growth)} periods")

# COMMAND ----------
# Export all dashboard DataFrames
print("\n=== Exporting Dashboard DataFrames ===")

dashboard_files = [
    (df_summary, "dashboard_summary.csv", "High-level summary metrics"),
    (df_industry, "dashboard_industry_performance.csv", "Industry performance by period"),
    (df_retention, "dashboard_retention_analysis.csv", "Retention rates by industry"),
    (df_top_industries, "dashboard_top_industries.csv", "Top performing industries"),
    (df_growth, "dashboard_growth_trends.csv", "Growth trends analysis")
]

for df, filename, description in dashboard_files:
    if len(df) > 0:
        # Export to CSV
        df.to_csv(f"/tmp/{filename}", index=False)
        dbutils.fs.cp(f"file:///tmp/{filename}", f"/FileStore/shared_uploads/{filename}")
        print(f"âœ“ Exported: {filename} ({len(df)} records) - {description}")

# COMMAND ----------
# Display sample data for verification
print("\n" + "="*80)
print("DASHBOARD DATAFRAMES PREVIEW")
print("="*80)

print(f"\n1. SUMMARY DASHBOARD ({len(df_summary)} periods):")
print(df_summary.to_string(index=False))

print(f"\n2. INDUSTRY PERFORMANCE (Sample - Top 10):")
sample_industry = df_industry.head(10)
print(sample_industry.to_string(index=False))

print(f"\n3. RETENTION ANALYSIS (Sample - Top 10):")
sample_retention = df_retention.head(10)
print(sample_retention.to_string(index=False))

print(f"\n4. TOP INDUSTRIES:")
print(df_top_industries.to_string(index=False))

if len(df_growth) > 0:
    print(f"\n5. GROWTH TRENDS:")
    print(df_growth.to_string(index=False))

# COMMAND ----------
# Create executive summary
print("\n" + "="*80)
print("EXECUTIVE SUMMARY")
print("="*80)

if len(df_summary) > 0:
    latest = df_summary.iloc[-1]
    baseline = df_summary.iloc[0]
    
    print(f"Base Cohort Size: {constant_14m_count:,} merchants")
    print(f"Latest Period: {latest['period']}")
    print(f"Latest Retention Rate: {latest['retention_rate_pct']:.1f}%")
    print(f"Latest Active Merchants: {latest['active_merchants']:,}")
    print(f"Latest Transaction Volume: {latest['total_transactions']:,}")
    print(f"Latest Transaction Amount: ${latest['total_amount']:,.0f}")
    
    if len(df_summary) > 1:
        retention_change = latest['retention_rate_pct'] - baseline['retention_rate_pct']
        print(f"Retention Rate Change: {retention_change:+.1f}%")

print(f"\nTop Industry by Volume: NAICS {df_top_industries.iloc[0]['naics3']}")
print(f"Industries Tracked: {df_industry['naics3'].nunique()}")
print(f"Tracking Periods: {len(tracking_months)}")

print("\n" + "="*80)
print("DASHBOARD EXPORT COMPLETED")
print("All files available in /FileStore/shared_uploads/")
print("Ready for visualization and analysis")
print("="*80)
